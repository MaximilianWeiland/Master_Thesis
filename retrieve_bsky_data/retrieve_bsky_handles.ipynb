{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk==3.8.1\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.8.1\n"
     ]
    }
   ],
   "source": [
    "# install the requirements\n",
    "#!pip install atproto\n",
    "#!pip install pandas\n",
    "#!pip install nltk==3.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load requirements\n",
    "from atproto import Client\n",
    "import pandas as pd\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProfileViewDetailed(did='did:plc:5sqqg66p7muc7ogbp6xx4sw6', handle='mxwlnd.bsky.social', associated=ProfileAssociated(chat=None, feedgens=0, labeler=False, lists=0, starter_packs=0, py_type='app.bsky.actor.defs#profileAssociated'), avatar='https://cdn.bsky.app/img/avatar/plain/did:plc:5sqqg66p7muc7ogbp6xx4sw6/bafkreigwrjedzb7jvmowkn6fbe2atbnlwecsa4ouk5wpz54eg6rqkvayrq@jpeg', banner=None, created_at='2025-05-19T19:28:35.738Z', description=None, display_name='', followers_count=2, follows_count=1, indexed_at='2025-05-19T19:28:35.738Z', joined_via_starter_pack=None, labels=[], pinned_post=None, posts_count=0, verification=None, viewer=ViewerState(blocked_by=False, blocking=None, blocking_by_list=None, followed_by=None, following=None, known_followers=None, muted=False, muted_by_list=None, py_type='app.bsky.actor.defs#viewerState'), py_type='app.bsky.actor.defs#profileViewDetailed')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a client instance\n",
    "client = Client()\n",
    "\n",
    "# get the app password\n",
    "with open(\"app_password.txt\", \"r\") as f:\n",
    "    app_password = f.read()\n",
    "\n",
    "handle = \"mxwlnd.bsky.social\"\n",
    "\n",
    "# login with my credentials\n",
    "client.login(handle, app_password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the did of the list creator\n",
    "creator_handle = \"politicshome.bsky.social\"\n",
    "creator_profile = client.app.bsky.actor.get_profile({\"actor\": creator_handle})\n",
    "creator_did = creator_profile.did\n",
    "rkey = '3laetww5nlb23'             # the unique ID of the list\n",
    "\n",
    "# get all members on the list\n",
    "handles = []\n",
    "keep_looping = True\n",
    "cursor = None\n",
    "while keep_looping == True:\n",
    "    list_items = client.app.bsky.graph.get_list({\n",
    "        'list': f'at://{creator_did}/app.bsky.graph.list/{rkey}',\n",
    "        'cursor': cursor\n",
    "    })\n",
    "    for item in list_items.items:\n",
    "        did = item.subject.did\n",
    "        profile = client.app.bsky.actor.get_profile({'actor': did})\n",
    "        handles.append(profile.handle)\n",
    "    cursor = list_items[\"cursor\"]\n",
    "    if not cursor:\n",
    "        keep_looping = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that returns a df with all posts from given handle\n",
    "\n",
    "def retrieve_posts_to_df(list_handles):\n",
    "    data = []\n",
    "    for handle in list_handles:\n",
    "        did = client.com.atproto.identity.resolve_handle({'handle': handle})['did']\n",
    "        cursor = None\n",
    "        keep_looping = True\n",
    "\n",
    "        while keep_looping == True:\n",
    "            response = client.app.bsky.feed.get_author_feed({\n",
    "                'actor': did,\n",
    "                'cursor': cursor,\n",
    "                'limit': 100\n",
    "            })\n",
    "\n",
    "            # get the response feed\n",
    "            feed = response['feed']\n",
    "\n",
    "            for item in feed:\n",
    "                post = {}\n",
    "                post_handle = item[\"post\"][\"author\"][\"handle\"]\n",
    "                text = item[\"post\"][\"record\"][\"text\"]\n",
    "                date = item[\"post\"][\"record\"][\"created_at\"]\n",
    "\n",
    "                # filter out reposts\n",
    "                if handle == post_handle:\n",
    "                    post[\"handle\"] = handle\n",
    "                    post[\"date\"] = date\n",
    "                    post[\"text\"] = text\n",
    "                    data.append(post)\n",
    "\n",
    "            cursor = response['cursor']\n",
    "            if not cursor:\n",
    "                keep_looping = False\n",
    "\n",
    "        df = pd.DataFrame(data).sort_values(by=\"date\", ascending=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# retrieve the posts\n",
    "df = retrieve_posts_to_df(handles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define emoji patterns\n",
    "emoji_pattern = re.compile(\n",
    "    \"[\"\n",
    "    \"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "    \"\\U0001F300-\\U0001F5FF\"  # Symbols & pictographs\n",
    "    \"\\U0001F680-\\U0001F6FF\"  # Transport & map symbols\n",
    "    \"\\U0001F1E0-\\U0001F1FF\"  # Flags\n",
    "    \"\\U00002700-\\U000027BF\"  # Dingbats\n",
    "    \"\\U0001F900-\\U0001F9FF\"  # Supplemental symbols\n",
    "    \"\\U00002600-\\U000026FF\"  # Misc symbols\n",
    "    \"\\U00002500-\\U00002BEF\"  # Chinese characters and more\n",
    "    \"]+\",\n",
    "    flags=re.UNICODE,\n",
    ")\n",
    "hashtag_pattern = re.compile(r\"#\\w+\")\n",
    "url_pattern = re.compile(r\"http[s]?://\\S+|www\\.\\S+\")\n",
    "\n",
    "# define function that removes the emojis\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = emoji_pattern.sub(r'', text)\n",
    "        text = hashtag_pattern.sub(r'', text)\n",
    "        text = url_pattern.sub(r'', text)\n",
    "        return text.strip()\n",
    "    return text\n",
    "\n",
    "# apply it to the df\n",
    "df[\"text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "# drop missing or non-string text rows\n",
    "df = df[df[\"text\"].apply(lambda x: isinstance(x, str))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the posts into individual sentences and sample 250 from them\n",
    "all_sentences = [sentence for post in df[\"text\"] for sentence in sent_tokenize(post, language=\"english\")]\n",
    "\n",
    "# pull a random sample and convert it to a df\n",
    "annotation_sample = random.sample(all_sentences, 250)\n",
    "annotation_df = pd.DataFrame({\"sentence_id\": range(len(annotation_sample)),\n",
    "                              \"sentence\": annotation_sample,\n",
    "                              \"label\": \"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since Labour took office, 10,000 more children have been plunged into poverty by the refusal to scrap the two-child benefit cap.\n",
      "I'm looking for a Senior Caseworker to join my team based in Sheerness.\n",
      "I get messages about this from across the city, including where people have been hurt.\n",
      "This , as always, we celebrate your contribution.\n",
      "I marked  at Cancer Research UK’s parliamentary drop in, speaking to the charity about new diagnostic and treatment technologies.\n",
      "This , I hope every child has the chance to get to ‘know themselves to grow themselves’.\n",
      "A useful resource to find out about roadworks is here.\n",
      "We'll hear from planners, the council and police leaders as well as women themselves.\n",
      "It was the start of a strong working relationship between both Speakers representing their respective Houses.\n",
      "I was reassured today to hear the government reiterate its commitment to legislation that will protect leaseholders and ensure they get fair treatment.\n",
      "Action, not delay.\n",
      "We need sanctions on Israel until it finally ends its crimes and stops violating international law.\n",
      "Energy bills up 6.4% — while network providers raked in £4 billion in “excess” profits over four years.\n",
      "Growth is what lifts living standards, raises wages, boosts productivity.\n",
      "The pathways we should be following for growth and investment should begin with a bespoke UK-EU customs union - contributing 2.2% to UK GDP and generating an extra £25 billion in tax revenue for our public services.\n",
      "It's time for proper regulation of the sector.\n",
      "Today’s deal with the EU finally offers hope to British business that they can trade with Europe again without all the paperwork - be a red against red tape with me and join @labour4europe.bsky.social  fighting for our future not rehashing the past.\n",
      "All different communities and religions were present today - all proud Rochdalians united in making our town such a great place to live and work.\n",
      "Yes, @South Cambs is one of the \"heatwave winners\" as local authorities cash in on their investments in solar during this boom year.\n"
     ]
    }
   ],
   "source": [
    "for idx, row in annotation_df.iloc[1:20].iterrows():\n",
    "    print(row[\"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the full df and the annotations to the data folder\n",
    "df.to_csv(\"../data/british_mps_posts.csv\", index=False)\n",
    "annotation_df.to_csv(\"../data/sentences_for_annotation.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
